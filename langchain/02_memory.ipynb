{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b44c73-76bd-43a8-9000-439e457c7b39",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1c7e1e-391d-4782-ad6f-1a79b79ddd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe666cb7-ce87-450e-bf5f-f54294367e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8f9eac0-4429-4aa7-b386-c42db34210cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b12b7-677c-47f2-b751-fc482f2b1dc6",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf350ae-4089-4f7c-bd33-590f401f99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3b53d39-d4a5-4272-b644-bce6a04f0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbcd9736-b84d-4004-8083-326aca61dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f978e901-815b-4e5f-80b6-84b178e748c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello, Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi, my name is andrew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59151b2f-5a3d-442a-9c0f-916bbf9f8e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is andrew\n",
      "AI: Hello, Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sum of 1 + 1 is 2.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is 1+1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3c45374-61e8-438d-a2d6-2d8d5dfeb850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is andrew\n",
      "AI: Hello, Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1\n",
      "AI: The sum of 1 + 1 is 2.\n",
      "Human: what is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew, as you mentioned earlier.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='what is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfc5bb77-cf49-4475-8381-5aa4520a25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is andrew\n",
      "AI: Hello, Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1\n",
      "AI: The sum of 1 + 1 is 2.\n",
      "Human: what is my name?\n",
      "AI: Your name is Andrew, as you mentioned earlier.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baa45c91-0e02-48d7-8cfd-e36778b6bfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is andrew\\nAI: Hello, Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1\\nAI: The sum of 1 + 1 is 2.\\nHuman: what is my name?\\nAI: Your name is Andrew, as you mentioned earlier.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3a88fbb-6416-4b87-9bf0-c7979d47a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a42528-fff2-4071-a251-1c0bfa8669a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is andrew\\nAI: Hello, Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1\\nAI: The sum of 1 + 1 is 2.\\nHuman: what is my name?\\nAI: Your name is Andrew, as you mentioned earlier.\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59579e94-fa7a-4da3-ba52-ffe94bb7e6ae",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96573713-4b6a-4ead-8bef-66d2d6949986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8231e7f9-14a2-43b3-9023-8b69daba5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea505721-a4a0-432c-a495-b2adcd32c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b1a14f7-272a-48fa-bd26-25ba9ed6d4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3de03cd-8a30-420e-9a33-df3948529d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f1ade6-3434-4fb0-bcb2-f322ae2a05a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce756305-0f4a-4416-81b3-ef94f8010926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sum of 1+1 is 2.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18811c56-4f5f-4dd9-8a02-e92ef895be33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. So, I don't know your name.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900477f-c141-4576-be07-ee112adcf178",
   "metadata": {},
   "source": [
    "#### ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce7f7c04-6e7a-46a1-9b7b-226208999b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1938a150-dd8c-4e3a-bae7-00b0b61fc700",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    model=llm_model)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e27b076e-eab4-42eb-a3eb-d333830dcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88769fa0-9bbd-4f76-9911-4edad00b5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6941caf6-6068-44b3-b4c2-a8de04346d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Delightful!'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde71c3e-470c-4b7e-a96c-3e3a161ead8e",
   "metadata": {},
   "source": [
    "#### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f3c6602-5e5a-45d4-8d51-ce2555e2fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dc962e2-6381-4aa2-b07d-ab07f27ce57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcd982b5-42b9-4274-afc7-856cbdbaba96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings and the human asks about their schedule for the day. The AI informs them of a morning meeting with the product team, time set aside for working on the LangChain project, and a lunch meeting at an Italian restaurant with a customer interested in the latest in AI. The AI also reminds the human to bring their laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb08cb53-9a06-4a75-9b52-8ec04f15a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4bf7d08-c3de-42f1-86f5-32ceb16be903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings and the human asks about their schedule for the day. The AI informs them of a morning meeting with the product team, time set aside for working on the LangChain project, and a lunch meeting at an Italian restaurant with a customer interested in the latest in AI. The AI also reminds the human to bring their laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show would be the latest version of our Language Learning Model (LLM). This model has been updated with new features such as real-time translation, personalized language learning paths, and an interactive interface. It would be beneficial to demonstrate how these features work in real-time. Additionally, you could show the customer how the model adapts to different learning styles and paces, which could be a key selling point.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01fc797a-ed7b-4d16-9e4c-5f512408ddb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings and the human asks about their schedule for the day. The AI informs them of a morning meeting with the product team, time set aside for working on the LangChain project, and a lunch meeting at an Italian restaurant with a customer interested in the latest in AI. The AI also reminds the human to bring their laptop to show the latest LLM demo. The human then asks the AI for suggestions on a good demo to show.\\nAI: A good demo to show would be the latest version of our Language Learning Model (LLM). This model has been updated with new features such as real-time translation, personalized language learning paths, and an interactive interface. It would be beneficial to demonstrate how these features work in real-time. Additionally, you could show the customer how the model adapts to different learning styles and paces, which could be a key selling point.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d16346-212d-4296-aa2a-5b2fd6b721ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
